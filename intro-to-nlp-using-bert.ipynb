{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb64a7bb",
   "metadata": {
    "papermill": {
     "duration": 0.017937,
     "end_time": "2022-01-08T19:48:48.770623",
     "exception": false,
     "start_time": "2022-01-08T19:48:48.752686",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**1. What is BERT?**\n",
    "\n",
    "\n",
    "BERT, which stands for Bidirectional Encoder Representations from Transformers, is based on Transformers, a deep learning model in which every output element is connected to every input element, and the weightings between them are dynamically calculated based upon their connection.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52975002",
   "metadata": {
    "papermill": {
     "duration": 0.016537,
     "end_time": "2022-01-08T19:48:48.805846",
     "exception": false,
     "start_time": "2022-01-08T19:48:48.789309",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**2. Why BERT?**\n",
    "\n",
    "BERT was built upon recent work and clever ideas in pre-training contextual representations including Semi-supervised Sequence Learning, Generative Pre-Training, ELMo, the OpenAI Transformer, ULMFit and the Transformer. Although these models are all unidirectional or shallowly bidirectional, BERT is fully bidirectional.\n",
    "BERT gives it incredible accuracy and performance on smaller data sets which solves a huge problem in natural language processing.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4b6b6b",
   "metadata": {
    "papermill": {
     "duration": 0.016692,
     "end_time": "2022-01-08T19:48:48.839326",
     "exception": false,
     "start_time": "2022-01-08T19:48:48.822634",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**3. How does it work?**\n",
    "\n",
    "BERT relies on a Transformer (the attention mechanism that learns contextual relationships between words in a text). A basic Transformer consists of an encoder to read the text input and a decoder to produce a prediction for the task. Since BERTâ€™s goal is to generate a language representation model, it only needs the encoder part. The input to the encoder for BERT is a sequence of tokens, which are first converted into vectors and then processed in the neural network. But before processing can start, BERT needs the input to be massaged and decorated with some extra metadata:\n",
    "\n",
    "Token embeddings: A [CLS] token is added to the input word tokens at the beginning of the first sentence and a [SEP] token is inserted at the end of each sentence.\n",
    "Segment embeddings: A marker indicating Sentence A or Sentence B is added to each token. This allows the encoder to distinguish between sentences.\n",
    "Positional embeddings: A positional embedding is added to each token to indicate its position in the sentence.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d980ae23",
   "metadata": {
    "papermill": {
     "duration": 0.016561,
     "end_time": "2022-01-08T19:48:48.872812",
     "exception": false,
     "start_time": "2022-01-08T19:48:48.856251",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**4. How to use BERT?**\n",
    "\n",
    "BERT can be used for a wide variety of language tasks, while only adding a small layer to the core model: \n",
    "1. Classification tasks such as sentiment analysis are done similarly to Next Sentence classification, by adding a classification layer on top of the Transformer output for the [CLS] token. \n",
    "2. In Question Answering tasks (e.g. SQuAD v1.1), the software receives a question regarding a text sequence and is required to mark the answer in the sequence. Using BERT, a Q&A model can be trained by learning two extra vectors that mark the beginning and the end of the answer.\n",
    "3. In Named Entity Recognition (NER), the software receives a text sequence and is required to mark the various types of entities (Person, Organization, Date, etc) that appear in the text. Using BERT, a NER model can be trained by feeding the output vector of each token into a classification layer that predicts the NER label."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e1ec09",
   "metadata": {
    "papermill": {
     "duration": 0.016646,
     "end_time": "2022-01-08T19:48:48.906210",
     "exception": false,
     "start_time": "2022-01-08T19:48:48.889564",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Import Libraries and Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60ea0bb0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-08T19:48:48.951283Z",
     "iopub.status.busy": "2022-01-08T19:48:48.950496Z",
     "iopub.status.idle": "2022-01-08T19:48:48.957460Z",
     "shell.execute_reply": "2022-01-08T19:48:48.956796Z",
     "shell.execute_reply.started": "2022-01-08T19:37:17.545869Z"
    },
    "papermill": {
     "duration": 0.034734,
     "end_time": "2022-01-08T19:48:48.957627",
     "exception": false,
     "start_time": "2022-01-08T19:48:48.922893",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/nlp-getting-started/sample_submission.csv\n",
      "/kaggle/input/nlp-getting-started/train.csv\n",
      "/kaggle/input/nlp-getting-started/test.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62009bf1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-08T19:48:48.998480Z",
     "iopub.status.busy": "2022-01-08T19:48:48.997777Z",
     "iopub.status.idle": "2022-01-08T19:48:49.878834Z",
     "shell.execute_reply": "2022-01-08T19:48:49.878078Z",
     "shell.execute_reply.started": "2022-01-08T19:37:17.562825Z"
    },
    "papermill": {
     "duration": 0.902631,
     "end_time": "2022-01-08T19:48:49.878968",
     "exception": false,
     "start_time": "2022-01-08T19:48:48.976337",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import BERT tokenization\n",
    "\n",
    "!wget --quiet https://raw.githubusercontent.com/tensorflow/models/master/official/nlp/bert/tokenization.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b39dae84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-08T19:48:49.919321Z",
     "iopub.status.busy": "2022-01-08T19:48:49.918524Z",
     "iopub.status.idle": "2022-01-08T19:48:55.584416Z",
     "shell.execute_reply": "2022-01-08T19:48:55.584874Z",
     "shell.execute_reply.started": "2022-01-08T19:37:18.662225Z"
    },
    "papermill": {
     "duration": 5.688653,
     "end_time": "2022-01-08T19:48:55.585032",
     "exception": false,
     "start_time": "2022-01-08T19:48:49.896379",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tokenization\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7c1b1df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-08T19:48:55.624569Z",
     "iopub.status.busy": "2022-01-08T19:48:55.623943Z",
     "iopub.status.idle": "2022-01-08T19:48:55.690879Z",
     "shell.execute_reply": "2022-01-08T19:48:55.690380Z",
     "shell.execute_reply.started": "2022-01-08T19:37:18.669309Z"
    },
    "papermill": {
     "duration": 0.088294,
     "end_time": "2022-01-08T19:48:55.690995",
     "exception": false,
     "start_time": "2022-01-08T19:48:55.602701",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data=pd.read_csv('../input/nlp-getting-started/train.csv')\n",
    "test_data=pd.read_csv('../input/nlp-getting-started/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de775b56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-08T19:48:55.733219Z",
     "iopub.status.busy": "2022-01-08T19:48:55.728519Z",
     "iopub.status.idle": "2022-01-08T19:48:55.745079Z",
     "shell.execute_reply": "2022-01-08T19:48:55.745581Z",
     "shell.execute_reply.started": "2022-01-08T19:37:18.710460Z"
    },
    "papermill": {
     "duration": 0.036698,
     "end_time": "2022-01-08T19:48:55.745731",
     "exception": false,
     "start_time": "2022-01-08T19:48:55.709033",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91a3fd5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-08T19:48:55.790738Z",
     "iopub.status.busy": "2022-01-08T19:48:55.789227Z",
     "iopub.status.idle": "2022-01-08T19:48:55.793338Z",
     "shell.execute_reply": "2022-01-08T19:48:55.793741Z",
     "shell.execute_reply.started": "2022-01-08T19:37:18.723979Z"
    },
    "papermill": {
     "duration": 0.029228,
     "end_time": "2022-01-08T19:48:55.793869",
     "exception": false,
     "start_time": "2022-01-08T19:48:55.764641",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text\n",
       "0   0     NaN      NaN                 Just happened a terrible car crash\n",
       "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
       "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
       "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
       "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3182ed08",
   "metadata": {
    "papermill": {
     "duration": 0.017863,
     "end_time": "2022-01-08T19:48:55.829769",
     "exception": false,
     "start_time": "2022-01-08T19:48:55.811906",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Label encoding of labels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a162aca1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-08T19:48:55.873199Z",
     "iopub.status.busy": "2022-01-08T19:48:55.872244Z",
     "iopub.status.idle": "2022-01-08T19:48:55.876763Z",
     "shell.execute_reply": "2022-01-08T19:48:55.877341Z",
     "shell.execute_reply.started": "2022-01-08T19:37:18.739356Z"
    },
    "papermill": {
     "duration": 0.029466,
     "end_time": "2022-01-08T19:48:55.877536",
     "exception": false,
     "start_time": "2022-01-08T19:48:55.848070",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "label = preprocessing.LabelEncoder()\n",
    "y = label.fit_transform(train_data['target'])\n",
    "y = to_categorical(y)\n",
    "print(y[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282a5dc5",
   "metadata": {
    "papermill": {
     "duration": 0.018001,
     "end_time": "2022-01-08T19:48:55.914934",
     "exception": false,
     "start_time": "2022-01-08T19:48:55.896933",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Build a BERT layer**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60aea206",
   "metadata": {
    "papermill": {
     "duration": 0.018149,
     "end_time": "2022-01-08T19:48:55.951354",
     "exception": false,
     "start_time": "2022-01-08T19:48:55.933205",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**we create a BERT embedding layer by importing the BERT model from hub.KerasLayer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98cd0867",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-08T19:48:55.991659Z",
     "iopub.status.busy": "2022-01-08T19:48:55.991114Z",
     "iopub.status.idle": "2022-01-08T19:49:28.055566Z",
     "shell.execute_reply": "2022-01-08T19:49:28.054975Z",
     "shell.execute_reply.started": "2022-01-08T19:37:18.750260Z"
    },
    "papermill": {
     "duration": 32.086261,
     "end_time": "2022-01-08T19:49:28.055756",
     "exception": false,
     "start_time": "2022-01-08T19:48:55.969495",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-08 19:49:13.915729: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-08 19:49:14.004929: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-08 19:49:14.005729: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-08 19:49:14.006918: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-01-08 19:49:14.007948: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-08 19:49:14.008647: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-08 19:49:14.009268: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-08 19:49:15.727937: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-08 19:49:15.728749: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-08 19:49:15.729378: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-08 19:49:15.729973: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    }
   ],
   "source": [
    "module_url = \"https://tfhub.dev/tensorflow/bert_en_uncased_L-24_H-1024_A-16/1\"\n",
    "bert_layer = hub.KerasLayer(module_url, trainable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940d4879",
   "metadata": {
    "papermill": {
     "duration": 0.018641,
     "end_time": "2022-01-08T19:49:28.095550",
     "exception": false,
     "start_time": "2022-01-08T19:49:28.076909",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Encoding the text**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978d92b2",
   "metadata": {
    "papermill": {
     "duration": 0.018482,
     "end_time": "2022-01-08T19:49:28.133980",
     "exception": false,
     "start_time": "2022-01-08T19:49:28.115498",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "we create a BERT vocab_file in the form a numpy array. We then set the text to lowercase and finally we pass our vocab_file and do_lower_case variables to the Tokenizer object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3dd97270",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-08T19:49:28.184265Z",
     "iopub.status.busy": "2022-01-08T19:49:28.183476Z",
     "iopub.status.idle": "2022-01-08T19:49:28.292590Z",
     "shell.execute_reply": "2022-01-08T19:49:28.291770Z",
     "shell.execute_reply.started": "2022-01-08T19:37:36.713985Z"
    },
    "papermill": {
     "duration": 0.14006,
     "end_time": "2022-01-08T19:49:28.292717",
     "exception": false,
     "start_time": "2022-01-08T19:49:28.152657",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
    "tokenizer = tokenization.FullTokenizer(vocab_file, do_lower_case)\n",
    "def bert_encode(texts, tokenizer, max_len=60):\n",
    "    all_tokens = []\n",
    "    all_masks = []\n",
    "    all_segments = []\n",
    "    \n",
    "    for text in texts:\n",
    "        text = tokenizer.tokenize(text)\n",
    "        \n",
    "        text = text[:max_len-2]\n",
    "        input_sequence = [\"[CLS]\"] + text + [\"[SEP]\"]\n",
    "        pad_len = max_len-len(input_sequence)\n",
    "        \n",
    "        tokens = tokenizer.convert_tokens_to_ids(input_sequence) + [0] * pad_len\n",
    "        pad_masks = [1] * len(input_sequence) + [0] * pad_len\n",
    "        segment_ids = [0] * max_len\n",
    "        \n",
    "        all_tokens.append(tokens)\n",
    "        all_masks.append(pad_masks)\n",
    "        all_segments.append(segment_ids)\n",
    "        \n",
    "    return np.array(all_tokens), np.array(all_masks), np.array(all_segments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492dbd41",
   "metadata": {
    "papermill": {
     "duration": 0.01862,
     "end_time": "2022-01-08T19:49:28.330303",
     "exception": false,
     "start_time": "2022-01-08T19:49:28.311683",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Build The Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892adda8",
   "metadata": {
    "papermill": {
     "duration": 0.018621,
     "end_time": "2022-01-08T19:49:28.367767",
     "exception": false,
     "start_time": "2022-01-08T19:49:28.349146",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now we are all set to create our model. To do so, we will create a function named build_model that having tf.keras.models.Model class. Inside the function we will define our model layers. Our model will consist of three Dense neural network layers and also dropout layer. We have chosen a learning rate to 1e-5.\n",
    "\n",
    "RELU function :- With default values, this returns max(x, 0), the element-wise maximum of 0 and the input tensor. Modifying default parameters allows you to use non-zero thresholds, change the max value of the activation, and to use a non-zero multiple of the input for values below the threshold.\n",
    "\n",
    "Softmax function :- Softmax converts a real vector to a vector of categorical probabilities. The elements of the output vector are in range (0, 1) and sum to 1. Each vector is handled independently. The axis argument sets which axis of the input the function is applied along. Softmax is often used as the activation for the last layer of a classification network because the result could be interpreted as a probability distribution. The softmax of each vector x is computed as exp(x) / tf.reduce_sum(exp(x)).\n",
    "\n",
    "Binary corssentropy:- Computes the cross-entropy loss between true labels and predicted labels. We can use this cross-entropy loss when there are only two label classes (assumed to be 0 and 1). For each example, there should be a single floating-point value per prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0171ec2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-08T19:49:28.415349Z",
     "iopub.status.busy": "2022-01-08T19:49:28.413762Z",
     "iopub.status.idle": "2022-01-08T19:49:28.415942Z",
     "shell.execute_reply": "2022-01-08T19:49:28.416331Z",
     "shell.execute_reply.started": "2022-01-08T19:37:36.833960Z"
    },
    "papermill": {
     "duration": 0.029956,
     "end_time": "2022-01-08T19:49:28.416484",
     "exception": false,
     "start_time": "2022-01-08T19:49:28.386528",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_model(bert_layer, max_len=60):\n",
    "    input_word_ids = layers.Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n",
    "    input_mask = layers.Input(shape=(max_len,), dtype=tf.int32, name=\"input_mask\")\n",
    "    segment_ids = layers.Input(shape=(max_len,), dtype=tf.int32, name=\"segment_ids\")\n",
    "    _, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n",
    "    clf_output = sequence_output[:, 0, :]\n",
    "    out = layers.Dense(1, activation='sigmoid')(clf_output)\n",
    "    model = models.Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=out)\n",
    "    model.compile(optimizers.Adam(lr=1e-5), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa88a928",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-08T19:49:28.485231Z",
     "iopub.status.busy": "2022-01-08T19:49:28.467261Z",
     "iopub.status.idle": "2022-01-08T19:49:35.334401Z",
     "shell.execute_reply": "2022-01-08T19:49:35.333916Z",
     "shell.execute_reply.started": "2022-01-08T19:37:36.844726Z"
    },
    "papermill": {
     "duration": 6.899457,
     "end_time": "2022-01-08T19:49:35.334551",
     "exception": false,
     "start_time": "2022-01-08T19:49:28.435094",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = train_data.fillna(' ')\n",
    "test = test_data.fillna(' ')\n",
    "max_len = 60\n",
    "train_input = bert_encode(train['location']+' '+train['keyword']+' '+train['text'], tokenizer, max_len=max_len)\n",
    "test_input = bert_encode(test['location']+' '+test['keyword']+' '+test['text'], tokenizer, max_len=max_len)\n",
    "train_labels = train.target.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "048b13cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-08T19:49:35.377589Z",
     "iopub.status.busy": "2022-01-08T19:49:35.377021Z",
     "iopub.status.idle": "2022-01-08T19:49:35.381261Z",
     "shell.execute_reply": "2022-01-08T19:49:35.380851Z",
     "shell.execute_reply.started": "2022-01-08T19:37:42.999756Z"
    },
    "papermill": {
     "duration": 0.027687,
     "end_time": "2022-01-08T19:49:35.381363",
     "exception": false,
     "start_time": "2022-01-08T19:49:35.353676",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "labels = label.classes_\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69c829a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-08T19:49:35.436575Z",
     "iopub.status.busy": "2022-01-08T19:49:35.429457Z",
     "iopub.status.idle": "2022-01-08T19:49:36.534746Z",
     "shell.execute_reply": "2022-01-08T19:49:36.535321Z",
     "shell.execute_reply.started": "2022-01-08T19:37:43.008178Z"
    },
    "papermill": {
     "duration": 1.135438,
     "end_time": "2022-01-08T19:49:36.535525",
     "exception": false,
     "start_time": "2022-01-08T19:49:35.400087",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_word_ids (InputLayer)     [(None, 60)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_mask (InputLayer)         [(None, 60)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "segment_ids (InputLayer)        [(None, 60)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "keras_layer (KerasLayer)        [(None, 1024), (None 335141889   input_word_ids[0][0]             \n",
      "                                                                 input_mask[0][0]                 \n",
      "                                                                 segment_ids[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem (Slici (None, 1024)         0           keras_layer[0][1]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            1025        tf.__operators__.getitem[0][0]   \n",
      "==================================================================================================\n",
      "Total params: 335,142,914\n",
      "Trainable params: 335,142,913\n",
      "Non-trainable params: 1\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    }
   ],
   "source": [
    "model = build_model(bert_layer, max_len=max_len)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d180363d",
   "metadata": {
    "papermill": {
     "duration": 0.019173,
     "end_time": "2022-01-08T19:49:36.575122",
     "exception": false,
     "start_time": "2022-01-08T19:49:36.555949",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Run the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "585726eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-08T19:49:36.619224Z",
     "iopub.status.busy": "2022-01-08T19:49:36.618484Z",
     "iopub.status.idle": "2022-01-08T19:59:28.602369Z",
     "shell.execute_reply": "2022-01-08T19:59:28.602906Z",
     "shell.execute_reply.started": "2022-01-08T19:37:43.662809Z"
    },
    "papermill": {
     "duration": 592.008719,
     "end_time": "2022-01-08T19:59:28.603088",
     "exception": false,
     "start_time": "2022-01-08T19:49:36.594369",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-08 19:49:36.670660: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "381/381 [==============================] - 193s 424ms/step - loss: 0.4414 - accuracy: 0.8069 - val_loss: 0.3861 - val_accuracy: 0.8359\n",
      "Epoch 2/3\n",
      "381/381 [==============================] - 159s 417ms/step - loss: 0.2605 - accuracy: 0.8969 - val_loss: 0.4046 - val_accuracy: 0.8418\n",
      "Epoch 3/3\n",
      "381/381 [==============================] - 159s 416ms/step - loss: 0.1116 - accuracy: 0.9596 - val_loss: 0.5223 - val_accuracy: 0.8280\n"
     ]
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint('model.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "train_history = model.fit(\n",
    "    train_input, train_labels,\n",
    "    validation_split=0.2,\n",
    "    epochs=3,\n",
    "    callbacks=[checkpoint],\n",
    "    batch_size=16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1a3d831",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-08T19:59:29.237379Z",
     "iopub.status.busy": "2022-01-08T19:59:29.236519Z",
     "iopub.status.idle": "2022-01-08T20:00:00.142975Z",
     "shell.execute_reply": "2022-01-08T20:00:00.143742Z",
     "shell.execute_reply.started": "2022-01-08T19:47:34.643302Z"
    },
    "papermill": {
     "duration": 31.229717,
     "end_time": "2022-01-08T20:00:00.143925",
     "exception": false,
     "start_time": "2022-01-08T19:59:28.914208",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.load_weights('model.h5')\n",
    "test_pred = model.predict(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fbe23c08",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-08T20:00:00.804821Z",
     "iopub.status.busy": "2022-01-08T20:00:00.804135Z",
     "iopub.status.idle": "2022-01-08T20:00:00.827213Z",
     "shell.execute_reply": "2022-01-08T20:00:00.826752Z",
     "shell.execute_reply.started": "2022-01-08T19:48:09.326732Z"
    },
    "papermill": {
     "duration": 0.341241,
     "end_time": "2022-01-08T20:00:00.827329",
     "exception": false,
     "start_time": "2022-01-08T20:00:00.486088",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission = pd.read_csv(\"/kaggle/input/nlp-getting-started/sample_submission.csv\")\n",
    "submission['target'] = test_pred.round().astype(int)\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4c549f",
   "metadata": {
    "papermill": {
     "duration": 0.540766,
     "end_time": "2022-01-08T20:00:01.677439",
     "exception": false,
     "start_time": "2022-01-08T20:00:01.136673",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 684.597161,
   "end_time": "2022-01-08T20:00:05.363664",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-01-08T19:48:40.766503",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
